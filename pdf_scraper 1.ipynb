{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd711a6-db4a-408a-b7e7-70331cc86e80",
   "metadata": {},
   "source": [
    "# PDF Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbebc25-e7ac-4797-8d11-e8df9ff9f08a",
   "metadata": {},
   "source": [
    "Copyright (c) 2025 Go2Market Insights, Inc\n",
    "All rights reserved.\n",
    "https://g2m.ai\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions\n",
    "of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO\n",
    "THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n",
    "TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e183a-9376-4314-83dd-5c3cd78b84ca",
   "metadata": {},
   "source": [
    "## Add Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f33e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\clayarnold\\anaconda3\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\clayarnold\\anaconda3\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\clayarnold\\anaconda3\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\clayarnold\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\clayarnold\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.21)\n",
      "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------  5.5/5.6 MB 41.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 26.4 MB/s eta 0:00:00\n",
      "Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 87.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4825b2cf-199a-4efb-aa37-894140e2033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "import pdfplumber\n",
    "import re\n",
    "import typing\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from abc import ABC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85446d4-112d-41f3-aabc-e8e22fcc7676",
   "metadata": {},
   "source": [
    "## LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88fc47ed-73d4-4c44-8cb4-44f4006e6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUEST_TIMEOUT = 70 # in seconds\n",
    "LLM_TEMPERATURE = 0.5\n",
    "LLM_MAX_TOKENS = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4b3bd-e283-4c6e-a5f2-185534617806",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_ENDPOINTS = {\n",
    "    'example_model_name': {\n",
    "\t\t'best': {\n",
    "\t\t\t'url': '', # URL GOES HERE, \n",
    "            'key': '', # KEY GOES HERE,\n",
    "            'model_name': None, # Only necessary if model requires it (e.g. Some mistral models do require it)\n",
    "\t\t}, \n",
    "\t\t'fast': {\n",
    "            'url': None, # URL GOES HERE, \n",
    "            'key': None, # KEY GOES HERE,\n",
    "            'model_name': None, # Only necessary if model requires it (e.g. Some mistral models do require it)\n",
    "        }\n",
    "    }, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9424b4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27b0d9c8-4429-49a1-bc26-0e0b7799785a",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9b2cf09-a7a6-4516-b9e0-415ee5617e8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# G2M PDFParser\n",
    "class g2mPDFParser:\n",
    "    \"\"\"\n",
    "    Class handling i/o with the LLM \n",
    "    \n",
    "    \"\"\"\n",
    "    # INITIALIZATION\n",
    "    def __init__(self, llm='mistral', query_type='best'):\n",
    "        \"\"\"\n",
    "        Initialize class instance \n",
    "\n",
    "        \"\"\"\n",
    "        match llm:\n",
    "            # case 'mistral' | 'mistral-nemo' | 'mistral2_2411' | 'mistral-small':\n",
    "            #     self.__llm = g2mLLMClientMistral(llm_type=llm, query_type=query_type)\n",
    "            case 'llama3_1_small' | 'llama3_1_large' | 'llama3_3':\n",
    "                self.__llm = g2mLLMClientLlama(llm_type=llm, query_type=query_type)\n",
    "            case _:\n",
    "                print('Unknown LLM type', f'llm_type={llm}')\n",
    "                self.__llm = None \n",
    "\n",
    "    # READ IN TEXT FILE\n",
    "    def read_in_text_file(self, file):\n",
    "        with open(file, \"r\") as file:\n",
    "            string = file.read()\n",
    "        return string\n",
    "\n",
    "    # GET FILE PATHS\n",
    "    def get_file_paths(folder_path):\n",
    "        file_paths = []\n",
    "        for root, directories, files in os.walk(folder_path):\n",
    "            for filename in files:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                file_paths.append(file_path)\n",
    "        return file_paths\n",
    "        \n",
    "    # CONVERT TO TEXT\n",
    "    def convert_to_text(self, pdf, filepath=None, save=True):\n",
    "        with pdfplumber.open(pdf) as pdf2:\n",
    "            page = pdf2.pages[0]\n",
    "            text = page.extract_text()\n",
    "            print(pdf)\n",
    "            # print(text, \"\\n\")\n",
    "            #Save new text files\n",
    "            if save: \n",
    "                root, ext = os.path.splitext(pdf)\n",
    "                file = open(f'{root}-pdfplumber.txt',\"w\")\n",
    "                file.write(text)\n",
    "                file.close()\n",
    "    \n",
    "        return\n",
    "\n",
    "    # CONVERT PDF(s)\n",
    "    def convert_pdfs(self, files, filepath=None):\n",
    "        for file in files:\n",
    "            root, ext = os.path.splitext(file)\n",
    "            if ext == \".pdf\":\n",
    "                try: \n",
    "                    self.convert_to_text(file, 'C:\\\\filepath')\n",
    "                except: \n",
    "                    print(\"Warning! PDF could not be converted. \", file)\n",
    "\n",
    "    # BULK ANSWER AND SAVE\n",
    "    def bulk_answer_and_save(self, system='', files=None, save=False, filepath=None):\n",
    "        for file in files: \n",
    "            user = self.read_in_text_file(file)\n",
    "            res = self.query(user=user, system=system)\n",
    "            obj = json.loads(res.content)\n",
    "            text = obj['choices'][0]['text']\n",
    "            #filepath = \"\"\n",
    "            print(text, \"\\n\")\n",
    "            if save: \n",
    "                root, ext = os.path.splitext(file)\n",
    "                if filepath is not None: \n",
    "                    file = open(f'{root}-LLM-answer.txt',\"w\")\n",
    "                #print(file)\n",
    "                file.write(text)\n",
    "                file.close()\n",
    "        return\n",
    "        \n",
    "    # QUERY LLM\n",
    "    def query(self, user='', system='', temperature=LLM_TEMPERATURE, max_tokens=LLM_MAX_TOKENS, query_type='best'):\n",
    "        \"\"\"\n",
    "        Send query to LLM. The user query and system context are provided separately.\n",
    "        The full prompt is assembled here using the appropriate syntax. \n",
    "\n",
    "        :param user: user query, e.g. 'hello, how are you'\n",
    "        :param system: system context and role, e.g. 'you are business analyst'\n",
    "        :param temperature:\n",
    "        :param max_tokens:\n",
    "        :param query_type:\n",
    "        :return res:\n",
    "        \"\"\"\n",
    "        if self.__llm is not None:\n",
    "            res = self.__llm.query(user=user, system=system, temperature=temperature, max_tokens=max_tokens, query_type=query_type)\n",
    "        else:\n",
    "            print('LLM type unknown, aborting LLM query', type=self.__llm)\n",
    "            res = {'status': 'Unavailable', 'message': 'LLM type unknown'}\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "396a33b9-12f9-47b8-be4e-595a964a6c52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# G2M LLM CLIENT BASE CLASS\n",
    "class g2mLLMClientBase(ABC):\n",
    "    \"\"\"\n",
    "    Class handling i/o with the LLM \n",
    "    \n",
    "    \"\"\"\n",
    "    def setLLm(self, query_type='best'): \n",
    "        \"\"\"\n",
    "        Set the appropriate LLM, especially based on query_type attribute (e.g. 'best' || 'fast')\n",
    "\n",
    "        :param query_type:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self._url = LLM_ENDPOINTS[self._type][query_type]['url'] \n",
    "        self._api_key = LLM_ENDPOINTS[self._type][query_type]['key']\n",
    "        self._model_name = LLM_ENDPOINTS[self._type][query_type].get('model_name', None)\n",
    "        self._type = self._type\n",
    "        self._query_type = query_type\n",
    "\n",
    "    def query(self, user='', system='', temperature=LLM_TEMPERATURE, max_tokens=LLM_MAX_TOKENS, query_type='best'):\n",
    "        \"\"\"\n",
    "        Send query to LLM. The user query and systen context are provided separately.\n",
    "        The full prompt is assembled here using the appropriate syntax. \n",
    "\n",
    "        :param user: user query, e.g. 'hello, how are you'\n",
    "        :param system: system context and role, e.g. 'you are business analyst'\n",
    "        :param temperature:\n",
    "        :param max_tokens:\n",
    "        :param query_type:\n",
    "        :return res:\n",
    "        \"\"\"\n",
    "        self.setLLm(query_type=query_type)\n",
    "        body = {\n",
    "            'messages': [\n",
    "                {\n",
    "                    'role': 'system', \n",
    "                    'content': system, \n",
    "                }, \n",
    "                {\n",
    "                    'role': 'user', \n",
    "                    'content': user, \n",
    "                }, \n",
    "            ], \n",
    "            'temperature': temperature, \n",
    "            'max_tokens': max_tokens, \n",
    "        }\n",
    "        if self._model_name is not None: \n",
    "            print('Querying with model...', model_name=self._model_name)\n",
    "            body['model'] = self._model_name\n",
    "        return self._send_request(body)\n",
    "\n",
    "    def _send_request(self, body):\n",
    "        \"\"\"\n",
    "        Send JSON request to LLM API\n",
    "\n",
    "        :param body: \n",
    "        :return res:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self._url is not None and self._api_key is not None:\n",
    "                res = requests.post(\n",
    "                    self._url,\n",
    "                    json=body,\n",
    "                    headers={\n",
    "                        \"Accept\": \"*/*\",\n",
    "                        \"Content-Type\": \"application/json\",\n",
    "                        \"Authorization\": \"Bearer {}\".format(self._api_key),\n",
    "                    },\n",
    "                    timeout = REQUEST_TIMEOUT, \n",
    "                )\n",
    "                obj = json.loads(res.content)\n",
    "                text = self._parse_response(obj)\n",
    "                LLMObs.annotate(\n",
    "                    input_data=body['messages'],\n",
    "                    output_data=[{\"role\": \"assistant\", \"content\": text}],\n",
    "                    metadata={\n",
    "                        \"temperature\": body['temperature'], \n",
    "                        \"max_tokens\": body['temperature'], \n",
    "                        \"llm_type\": self._type, \n",
    "                    },\n",
    "                )\n",
    "                res = {'status': 'Successful', 'text': text}\n",
    "            elif self._url is None:\n",
    "                print('LLM URL not specified, aborting LLM query', url=self._url)\n",
    "                res = {'status': 'Unavailable', 'message': 'URL not specified'}\n",
    "            else:\n",
    "                print('LLM access parameters not valid', url=self._url)\n",
    "                res = {'status': 'Unavailable', 'message': 'Invalid access parameters'}\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Cannot send LLM request: {}'.format(e), url=self._url)\n",
    "            res = {'status': 'Unavailable', 'message': 'Cannot send request'}\n",
    "        \n",
    "        except:\n",
    "            print('Cannot send LLM request', url=self._url)\n",
    "            res = {'status': 'Unavailable', 'message': 'Cannot send request'}\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def _parse_response(self, obj):\n",
    "        \"\"\"\n",
    "        Parse LLM response\n",
    "\n",
    "        :param obj:\n",
    "        :return text:\n",
    "        \"\"\"\n",
    "        # log.debug('Parsing response...', obj=obj)\n",
    "        if 'object' in obj.keys() and obj['object']=='Error':\n",
    "            text = obj['message']\n",
    "        elif 'error' in obj.keys(): \n",
    "            # Check if 'message' is a stringified JSON\n",
    "            if isinstance(obj['error']['message'], str):\n",
    "                try:\n",
    "                    error_message = json.loads(obj['error']['message'])\n",
    "                    print(f'[_parse_response] LLM response returned with error: {error_message}')\n",
    "                    text = 'Unable to give a response.'\n",
    "                except json.JSONDecodeError: \n",
    "                    text = obj['error']['message']\n",
    "            else:\n",
    "                text = obj['error']['message'].get('message', 'Unable to give a response.')\n",
    "        else:\n",
    "            text = obj['choices'][0]['message']['content'].strip()\n",
    "        return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e993782b-d8ed-4b68-8447-823fa478541a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# G2M LLAMA LLM CLIENT\n",
    "class g2mLLMClientLlama(g2mLLMClientBase):\n",
    "    \"\"\"\n",
    "    Class handling i/o with the LLM \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm_type='llama3_1_small', query_type='best'):\n",
    "        \"\"\"\n",
    "        Initialize class instance \n",
    "\n",
    "        \"\"\"\n",
    "        self._url = LLM_ENDPOINTS[llm_type][query_type]['url'] \n",
    "        self._api_key = LLM_ENDPOINTS[llm_type][query_type]['key']\n",
    "        self._type = llm_type\n",
    "        self._query_type = query_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12bafae4-4aac-44b7-bb26-f1e0923affba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown LLM type llm_type=mistral\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "g2mPDFParser.convert_pdfs() missing 1 required positional argument: 'files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3_1_small\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m parser \u001b[38;5;241m=\u001b[39m g2mPDFParser()\n\u001b[1;32m----> 4\u001b[0m parser\u001b[38;5;241m.\u001b[39mconvert_pdfs()\n",
      "\u001b[1;31mTypeError\u001b[0m: g2mPDFParser.convert_pdfs() missing 1 required positional argument: 'files'"
     ]
    }
   ],
   "source": [
    "# Example Use of G2M PDF Parser: \n",
    "llm = 'llama3_1_small'\n",
    "parser = g2mPDFParser()\n",
    "parser.convert_pdfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb317c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
